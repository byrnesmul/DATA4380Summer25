{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **HW1**"
      ],
      "metadata": {
        "id": "RLILIKJeBy30"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Organize Dataset Directory\n",
        "\n",
        "Create a folder named `zip_files` and move all ZIP files into it. This ensures we can unzip them again later if we modify the CSV files.\n"
      ],
      "metadata": {
        "id": "gBFZu9WtDcnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a folder for zip files\n",
        "mkdir zip_files\n",
        "\n",
        "# Move all zip files into that folder\n",
        "mv *.zip zip_files/\n",
        "\n",
        "# List the contents to confirm\n",
        "ls zip_files\n"
      ],
      "metadata": {
        "id": "SfRSXs70B4bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Split `diabetes_prediction_dataset.csv` into 3 Equal Parts\n",
        "\n",
        "The dataset has 100,001 lines total (1 header + 100,000 rows).  \n",
        "We split it into 3 parts with ~33,333 rows each and included the header in all files.\n"
      ],
      "metadata": {
        "id": "0i_R8Zn2DQoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get total line count\n",
        "wc -l diabetes_prediction_dataset.csv\n",
        "\n",
        "# Create header in each file\n",
        "head -n 1 diabetes_prediction_dataset.csv > part1.csv\n",
        "head -n 1 diabetes_prediction_dataset.csv > part2.csv\n",
        "head -n 1 diabetes_prediction_dataset.csv > part3.csv\n",
        "\n",
        "# Split data into 3 parts\n",
        "tail -n +2 diabetes_prediction_dataset.csv | head -n 33333 >> part1.csv\n",
        "tail -n +33335 diabetes_prediction_dataset.csv | head -n 33333 >> part2.csv\n",
        "tail -n +66668 diabetes_prediction_dataset.csv >> part3.csv\n",
        "\n",
        "# Check line counts\n",
        "wc -l part1.csv\n",
        "wc -l part2.csv\n",
        "wc -l part3.csv\n"
      ],
      "metadata": {
        "id": "nmkiAeroDSqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Split `Heart_Disease_Prediction.csv` by Label\n",
        "\n",
        "We created two CSV files:\n",
        "- `heart_absence.csv` contains all rows labeled \"Absence\"\n",
        "- `heart_presence.csv` contains all rows labeled \"Presence\"\n",
        "\n",
        "Both include the header row.\n"
      ],
      "metadata": {
        "id": "vmTfBHf0ETx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add header to both files\n",
        "head -n 1 Heart_Disease_Prediction.csv > heart_absence.csv\n",
        "head -n 1 Heart_Disease_Prediction.csv > heart_presence.csv\n",
        "\n",
        "# Filter by label\n",
        "grep \"Absence\" Heart_Disease_Prediction.csv >> heart_absence.csv\n",
        "grep \"Presence\" Heart_Disease_Prediction.csv >> heart_presence.csv\n",
        "\n",
        "# Confirm counts\n",
        "wc -l heart_absence.csv\n",
        "wc -l heart_presence.csv\n"
      ],
      "metadata": {
        "id": "hfCjHyhuEUp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Fraction of Cars with No Accidents\n",
        "\n",
        "We used `grep` to find lines containing \"no accident\" and compared it to the total number of cars (excluding the header).\n"
      ],
      "metadata": {
        "id": "4fgBqx8BFgiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count rows with \"no accident\" (case-insensitive)\n",
        "grep -i \"no accident\" car_web_scraped_dataset.csv | wc -l\n",
        "\n",
        "# Count total cars (excluding header)\n",
        "tail -n +2 car_web_scraped_dataset.csv | wc -l\n",
        "\n",
        "# Compute the fraction manually: 2223 / 2840 ≈ 0.783\n"
      ],
      "metadata": {
        "id": "HWdmQwIYFhqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Replace Values in `Housing.csv` with Numbers\n",
        "\n",
        "We replaced:\n",
        "- \"yes\" → 1\n",
        "- \"no\" → 0\n",
        "- \"unfurnished\" → 0\n",
        "- \"furnished\" → 1\n",
        "- \"semi-furnished\" → 2\n",
        "\n",
        "The result is saved to a new file: `Housing_numeric.csv`\n"
      ],
      "metadata": {
        "id": "4MtGXEddFqYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace values using sed and save to new file\n",
        "sed -e 's/\\byes\\b/1/g' \\\n",
        "     -e 's/\\bno\\b/0/g' \\\n",
        "     -e 's/,unfurnished/,0/g' \\\n",
        "     -e 's/,semi-furnished/,2/g' \\\n",
        "     -e 's/,furnished/,1/g' \\\n",
        "     Housing.csv > Housing_numeric.csv\n",
        "\n",
        "# Preview result\n",
        "head Housing_numeric.csv\n"
      ],
      "metadata": {
        "id": "hzq_8DDYGPBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6: Remove the \"CustomerID\" Column from `Mall_Customers.csv`\n",
        "\n",
        "We used the `cut` command to remove the first column (CustomerID) and saved the result to a new file.\n"
      ],
      "metadata": {
        "id": "EKZROyd1GTiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the first column (CustomerID) and save to a new file\n",
        "cut -d ',' -f2- Mall_Customers.csv > Mall_Customers_no_id.csv\n",
        "\n",
        "# Preview the new file\n",
        "head Mall_Customers_no_id.csv\n"
      ],
      "metadata": {
        "id": "sFHf9eYQG9xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7: Compute Sum of 4 Score Columns from University Rankings\n",
        "\n",
        "We summed the following fields for each university:\n",
        "- Research Quality Score\n",
        "- Industry Score\n",
        "- International Outlook\n",
        "- Research Environment Score\n",
        "\n",
        "The results are saved in `university_score_sums.txt`.\n"
      ],
      "metadata": {
        "id": "s8P59lxbHDSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract columns 5–8 (skip header), convert to math expression, and compute sums\n",
        "tail -n +2 'world all university rank and rank score.csv' | \\\n",
        "cut -d ',' -f5-8 | \\\n",
        "tr ',' '+' | \\\n",
        "bc > university_score_sums.txt\n",
        "\n",
        "# Preview result\n",
        "head university_score_sums.txt\n"
      ],
      "metadata": {
        "id": "I8DatfSzHnEm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Step 8: Sort Cancer Patient Data by Age\n",
        "We sorted the `cancer patient data sets.csv` file by the **Age** column to create a new file `cancer_sorted_by_age.csv`, with rows ordered from youngest to oldest. The header row is preserved.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ws_i2fwkJbNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(head -n 1 'cancer patient data sets.csv' && tail -n +2 'cancer patient data sets.csv' | sort -t ',' -k3 -n) > cancer_sorted_by_age.csv\n"
      ],
      "metadata": {
        "id": "u6HlWK32KLNh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}